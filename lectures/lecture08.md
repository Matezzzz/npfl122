### Lecture: 8. SAC, Eligibility Traces
#### Date: Nov 22
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2122/slides/?08
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2122/slides.pdf/npfl122-08.pdf,PDF Slides
#### Lecture assignment: walker
#### Lecture assignment: walker_hardcore

- Soft actor-critic (SAC) [[Tuomas Haarnoja et al.: Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)]
- Off-policy correction using control varietes [Section 7.4 of RLB]
- Eligibility traces [Sections 12, 12.1, 12.3, 12.8, 12.9 of RLB]
- TD(Î») [Section 12.2 of RLB]
- The V-trace algorithm, IMPALA [[Lasse Espeholt et al.: IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561)]
